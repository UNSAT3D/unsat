{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#installation","title":"Installation","text":""},{"location":"#using-poetry-recommended","title":"Using <code>poetry</code> (recommended)","text":"<ol> <li>Running on Snellius? Read first the subsection below</li> <li>Clone repo: `git clone https://github.com/UNSAT3D/unsat.git</li> <li>Navigate to the project folder: <code>cd unsat</code></li> <li>If necessary install poetry: <code>pip install poetry</code></li> <li>Run <code>poetry install</code></li> </ol> <p>Your working environment can be activated via <code>poetry shell</code>, or to use it in a single command, prefix it with <code>poetry run</code>. More information on poetry available here.</p> <p>To access weights and biases, run <code>poetry run wandb login</code> once, and copy your API key found here.</p>"},{"location":"#weights-and-biases","title":"Weights and biases","text":"<p>We use weights and biases to track our experiments. Make sure this is set up first: make an account, find your API key and log in, following the instructions here.</p>"},{"location":"#usage","title":"Usage","text":"<p>Once installed, from the project folder run</p> <pre><code>poetry run python unsat/main.py fit -c configs/test_config.yaml --data.hdf5_path &lt;path to data&gt;\n</code></pre> <p>Note this assumes a GPU is available. If not, you can override the option by appending to the command above: <pre><code>--trainer.accelerator cpu\n</code></pre></p> <p>This does a short training run and uploads the results to weights and biases. In the terminal you should see a link to the run. The config used will be saved to weights and biases too as <code>lightning_config.yaml</code>.</p> <p>To do more useful runs, look at other config files or modify it yourself. All configuration settings should be in the config file rather than the code itself.</p> <p>Anything in one config can be overridden by a second one, or by single options as we do above for the data path. For instance to turn on profiling you can add: <code>--trainer.profiler pytorch</code>, or to use a predefined configured profiler, add <code>configs/profiler.yaml</code>.</p>"},{"location":"#snellius","title":"Snellius","text":"<p>On snellius, to install, run these commands: <pre><code>module load 2023\nmodule load Python/3.11.3-GCCcore-12.3.0\n</code></pre> and then follow the general instructions at the top.</p> <p>To submit a job, a basic script is provided, simply run (from the top project folder): <pre><code>sbatch scripts/run.slurm configs/test_config.yaml\n</code></pre></p> <p>This will create several outputs: - In <code>logs_slurm/</code>: The terminal output - In <code>wandb/</code>: The metadata of the run which is synced to weights and biases. - In <code>project-unsat/</code>: Model checkpoints and other data only stored locally.</p>"},{"location":"#contributing","title":"Contributing","text":""},{"location":"#linter","title":"Linter","text":""},{"location":"#remote","title":"Remote","text":"<p>The linter runs automatically every time you push a commit to GitHub.</p>"},{"location":"#local","title":"Local","text":"<p>If you want to use the linter locally, you'll have to install it manually:</p> <ol> <li>Activate your working environment (typically via <code>poetry shell</code>).</li> <li>Install <code>pre-commit</code> (by running <code>pre-commit install</code>).</li> </ol> <p>The linter will be executed after each commit. The linting will be performed automatically in case it is needed. The affected files will need staging and commiting again.</p>"},{"location":"CODE_OF_CONDUCT/","title":"Contributor Covenant Code of Conduct","text":""},{"location":"CODE_OF_CONDUCT/#our-pledge","title":"Our Pledge","text":"<p>We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation.</p> <p>We pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community.</p>"},{"location":"CODE_OF_CONDUCT/#our-standards","title":"Our Standards","text":"<p>Examples of behavior that contributes to a positive environment for our community include:</p> <ul> <li>Demonstrating empathy and kindness toward other people</li> <li>Being respectful of differing opinions, viewpoints, and experiences</li> <li>Giving and gracefully accepting constructive feedback</li> <li>Accepting responsibility and apologizing to those affected by our mistakes,   and learning from the experience</li> <li>Focusing on what is best not just for us as individuals, but for the   overall community</li> </ul> <p>Examples of unacceptable behavior include:</p> <ul> <li>The use of sexualized language or imagery, and sexual attention or   advances of any kind</li> <li>Trolling, insulting or derogatory comments, and personal or political attacks</li> <li>Public or private harassment</li> <li>Publishing others' private information, such as a physical or email   address, without their explicit permission</li> <li>Other conduct which could reasonably be considered inappropriate in a   professional setting</li> </ul>"},{"location":"CODE_OF_CONDUCT/#enforcement-responsibilities","title":"Enforcement Responsibilities","text":"<p>Community leaders are responsible for clarifying and enforcing our standards of acceptable behavior and will take appropriate and fair corrective action in response to any behavior that they deem inappropriate, threatening, offensive, or harmful.</p> <p>Community leaders have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, and will communicate reasons for moderation decisions when appropriate.</p>"},{"location":"CODE_OF_CONDUCT/#scope","title":"Scope","text":"<p>This Code of Conduct applies within all community spaces, and also applies when an individual is officially representing the community in public spaces. Examples of representing our community include using an official e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event.</p>"},{"location":"CODE_OF_CONDUCT/#enforcement","title":"Enforcement","text":"<p>Instances of abusive, harassing, or otherwise unacceptable behavior may be reported to the community leaders responsible for enforcement at s.ciarella@esciencecenter.nl. All complaints will be reviewed and investigated promptly and fairly.</p> <p>All community leaders are obligated to respect the privacy and security of the reporter of any incident.</p>"},{"location":"CODE_OF_CONDUCT/#enforcement-guidelines","title":"Enforcement Guidelines","text":"<p>Community leaders will follow these Community Impact Guidelines in determining the consequences for any action they deem in violation of this Code of Conduct:</p>"},{"location":"CODE_OF_CONDUCT/#1-correction","title":"1. Correction","text":"<p>Community Impact: Use of inappropriate language or other behavior deemed unprofessional or unwelcome in the community.</p> <p>Consequence: A private, written warning from community leaders, providing clarity around the nature of the violation and an explanation of why the behavior was inappropriate. A public apology may be requested.</p>"},{"location":"CODE_OF_CONDUCT/#2-warning","title":"2. Warning","text":"<p>Community Impact: A violation through a single incident or series of actions.</p> <p>Consequence: A warning with consequences for continued behavior. No interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, for a specified period of time. This includes avoiding interactions in community spaces as well as external channels like social media. Violating these terms may lead to a temporary or permanent ban.</p>"},{"location":"CODE_OF_CONDUCT/#3-temporary-ban","title":"3. Temporary Ban","text":"<p>Community Impact: A serious violation of community standards, including sustained inappropriate behavior.</p> <p>Consequence: A temporary ban from any sort of interaction or public communication with the community for a specified period of time. No public or private interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, is allowed during this period. Violating these terms may lead to a permanent ban.</p>"},{"location":"CODE_OF_CONDUCT/#4-permanent-ban","title":"4. Permanent Ban","text":"<p>Community Impact: Demonstrating a pattern of violation of community standards, including sustained inappropriate behavior,  harassment of an individual, or aggression toward or disparagement of classes of individuals.</p> <p>Consequence: A permanent ban from any sort of public interaction within the community.</p>"},{"location":"CODE_OF_CONDUCT/#attribution","title":"Attribution","text":"<p>This Code of Conduct is adapted from the Contributor Covenant, version 2.0, available at https://www.contributor-covenant.org/version/2/0/code_of_conduct.html.</p> <p>Community Impact Guidelines were inspired by Mozilla's code of conduct enforcement ladder.</p> <p>For answers to common questions about this code of conduct, see the FAQ at https://www.contributor-covenant.org/faq. Translations are available at https://www.contributor-covenant.org/translations.</p>"},{"location":"CONTRIBUTING/","title":"Contributing guidelines","text":"<p>Welcome! unsat is an open-source project for analysis of rooted soil. If you're trying unsat with your data, your experience, questions, bugs you encountered, and suggestions for improvement are important to the success of the project.</p> <p>We have a Code of Conduct, please follow it in all your interactions with the project.</p>"},{"location":"CONTRIBUTING/#questions-feedback-bugs","title":"Questions, feedback, bugs","text":"<p>Use the search function to see if someone else already ran across the same issue. Feel free to open a new issue here to ask a question, suggest improvements/new features, or report any bugs that you ran into.</p>"},{"location":"CONTRIBUTING/#submitting-changes","title":"Submitting changes","text":"<p>Even better than a good bug report is a fix for the bug or the implementation of a new feature. We welcome any contributions that help improve the code.</p> <p>When contributing to this repository, please first discuss the change you wish to make via an issue with the owners of this repository before making a change.</p> <p>Contributions can come in the form of:</p> <ul> <li>Bug fixes</li> <li>New features</li> <li>Improvement of existing code</li> <li>Updates to the documentation</li> <li>... ?</li> </ul> <p>We use the usual GitHub pull-request flow. For more info see GitHub's own documentation.</p> <p>Typically this means:</p> <ol> <li>Forking the repository and/or make a new branch</li> <li>Making your changes</li> <li>Make sure that the tests pass and add your own</li> <li>Update the documentation is updated for new features</li> <li>Pushing the code back to Github</li> <li>Create a new Pull Request</li> </ol> <p>One of the code owners will review your code and request changes if needed. Once your changes have been approved, your contributions will become part of unsat. \ud83c\udf89</p>"},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#macos-m1-arm64","title":"MacOS M1 arm64","text":"<p>Some dependencies (e.g. <code>scikit</code>) do not support the latest python version (3.12). Also <code>py3nj</code>, a dependency of <code>escnn</code>, requires openmp. We've installed this via homebrew and thus explicitly specifying the C compiler (gnu) prior to installation of this package does the trick.</p> <pre><code>conda create -n speckcn2 python=3.10\nconda activate speckcn2\nCC=gcc-13 pip3 install py3nj # install py3nj before with gcc instead of clang\npip install -e .\n</code></pre>"},{"location":"api/api/","title":"unsat","text":"<ul> <li>unsat.train</li> </ul>"},{"location":"api/train/","title":"train","text":""},{"location":"api/train/#unsat.train.Autoencoder","title":"<code>Autoencoder(base_channel_size, latent_dim, encoder_class=Encoder, decoder_class=Decoder, num_input_channels=3, width=32, height=32)</code>","text":"<p>               Bases: <code>LightningModule</code></p> Source code in <code>unsat/train.py</code> <pre><code>def __init__(\n    self,\n    base_channel_size: int,\n    latent_dim: int,\n    encoder_class: object = Encoder,\n    decoder_class: object = Decoder,\n    num_input_channels: int = 3,\n    width: int = 32,\n    height: int = 32,\n):\n    super().__init__()\n    # Saving hyperparameters of autoencoder\n    self.save_hyperparameters()\n    # Creating encoder and decoder\n    self.encoder = encoder_class(num_input_channels, base_channel_size, latent_dim)\n    self.decoder = decoder_class(num_input_channels, base_channel_size, latent_dim)\n    # Example input array needed for visualizing the graph of the network\n    self.example_input_array = torch.zeros(2, num_input_channels, width, height)\n</code></pre>"},{"location":"api/train/#unsat.train.Autoencoder.forward","title":"<code>forward(x)</code>","text":"<p>The forward function takes in an image and returns the reconstructed image.</p> Source code in <code>unsat/train.py</code> <pre><code>def forward(self, x):\n    \"\"\"The forward function takes in an image and returns the reconstructed image.\"\"\"\n    print(x.shape, flush=True)\n    breakpoint()\n    z = self.encoder(x)\n    x_hat = self.decoder(z)\n    return x_hat\n</code></pre>"},{"location":"api/train/#unsat.train.LightningTrainer","title":"<code>LightningTrainer(network, class_names, dimension, input_channels, optimizer, **kwargs)</code>","text":"<p>               Bases: <code>LightningModule</code></p> <p>Args:     network (nn.Module):         The network to train.     class_names (List[str]):         The names of the classes.     dimension (int):         The number of spatial dimensions.     input_channels (int):         The number of input channels.</p> Source code in <code>unsat/train.py</code> <pre><code>def __init__(\n    self,\n    network,\n    class_names,\n    dimension,\n    input_channels,\n    optimizer: OptimizerCallable,\n    **kwargs,\n):\n    \"\"\"\n    Lightning module defining the network and the training loop.\n\n    Args:\n        network (nn.Module):\n            The network to train.\n        class_names (List[str]):\n            The names of the classes.\n        dimension (int):\n            The number of spatial dimensions.\n        input_channels (int):\n            The number of input channels.\n    \"\"\"\n    torch.autograd.set_detect_anomaly(True)\n    super().__init__()\n    self.optimizer = optimizer\n\n    self.class_names = class_names\n    self.num_classes = len(class_names)\n\n    self.network = network\n    self.network.dimension = dimension\n    self.network.num_classes = self.num_classes\n    self.network.input_channels = input_channels\n    self.network.build()\n\n    metrics_args = dict(task=\"multiclass\", num_classes=self.num_classes, ignore_index=-1)\n    self.metrics = torch.nn.ModuleDict()\n    self.metrics[\"acc\"] = torch.nn.ModuleDict(\n        {\n            \"train_\": Accuracy(**metrics_args, average=\"macro\"),\n            \"val_\": Accuracy(**metrics_args, average=\"macro\"),\n        }\n    )\n    self.metrics[\"f1\"] = torch.nn.ModuleDict(\n        {\n            \"train_\": F1Score(**metrics_args, average=\"macro\"),\n            \"val_\": F1Score(**metrics_args, average=\"macro\"),\n        }\n    )\n    self.metrics[\"acc_per_class\"] = torch.nn.ModuleDict(\n        {\n            \"train_\": ClasswiseWrapper(\n                Accuracy(**metrics_args, average=None), labels=self.class_names\n            ),\n            \"val_\": ClasswiseWrapper(\n                Accuracy(**metrics_args, average=None), labels=self.class_names\n            ),\n        }\n    )\n    self.metrics[\"f1_per_class\"] = torch.nn.ModuleDict(\n        {\n            \"train_\": ClasswiseWrapper(\n                F1Score(**metrics_args, average=None), labels=self.class_names\n            ),\n            \"val_\": ClasswiseWrapper(\n                F1Score(**metrics_args, average=None), labels=self.class_names\n            ),\n        }\n    )\n\n    metrics_args[\"normalize\"] = \"true\"\n    self.metrics[\"confusion\"] = torch.nn.ModuleDict(\n        {\"train_\": ConfusionMatrix(**metrics_args), \"val_\": ConfusionMatrix(**metrics_args)}\n    )\n\n    # These can be overriden to represent class frequencies by using the ClassWeightsCallback\n    self.class_weights = torch.ones(self.num_classes)\n</code></pre>"},{"location":"api/train/#unsat.train.WandbSaveConfigCallback","title":"<code>WandbSaveConfigCallback</code>","text":"<p>               Bases: <code>SaveConfigCallback</code></p> <p>Custom callback to save the lightning config to wandb.</p>"}]}