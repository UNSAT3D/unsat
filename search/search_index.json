{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>Welcome to the UNSAT documentation! This guide provides a comprehensive overview of the UNSAT project, an AI analysis tool designed for rooted soil analysis. It will walk you through installation, usage, and other key aspects, ensuring you can leverage UNSAT effectively.</p>"},{"location":"#overview","title":"Overview","text":"<p>UNSAT is a Python-based tool tailored for analyzing and modeling rooted soils using AI techniques. It utilizes advanced configurations and integrates with tools like Weights and Biases (wandb) for experiment tracking and model evaluation. This documentation is divided into several sections to help you navigate and use UNSAT with ease.</p>"},{"location":"#table-of-contents","title":"Table of Contents","text":"<ol> <li>Introduction to UNSAT</li> <li>Installation Guide</li> <li>Using Poetry (Recommended)</li> <li>Snellius Installation</li> <li>Usage Instructions</li> <li>Running Experiments</li> <li>Weights and Biases Setup</li> <li>Configuration Management</li> <li>Overriding Configurations</li> <li>Profiling Options</li> <li>Contributing to UNSAT</li> <li>Using the Linter</li> <li>Contributing Guidelines</li> </ol>"},{"location":"#introduction-to-unsat","title":"Introduction to UNSAT","text":"<p>UNSAT is a specialized tool for analyzing soil structures, particularly focusing on rooted soils using machine learning and AI methodologies. The tool is designed to be flexible, allowing for a variety of configurations and setups to match different experimental needs. It integrates seamlessly with Weights and Biases for tracking experiments, and it is optimized to run efficiently on both local and remote environments, including HPC systems like Snellius.</p>"},{"location":"#installation-guide","title":"Installation Guide","text":""},{"location":"#using-poetry-recommended","title":"Using Poetry (Recommended)","text":"<p>Poetry is a dependency management tool that helps you manage your Python environments and dependencies efficiently. We highly recommend using Poetry to set up UNSAT. Follow these steps to get started:</p> <ol> <li> <p>Running on Snellius? Read first the subsection below</p> </li> <li> <p>Clone the Repository:    First, clone the UNSAT repository to your local machine:    <pre><code>git clone https://github.com/UNSAT3D/unsat.git\n</code></pre></p> </li> <li> <p>Navigate to the Project Folder:    Move into the cloned repository directory:    <pre><code>cd unsat\n</code></pre></p> </li> <li> <p>Install Poetry:    If Poetry is not already installed on your system, you can install it using pip:    <pre><code>pip install poetry\n</code></pre></p> </li> <li> <p>Install Dependencies:    Run the following command to install all required dependencies:    <pre><code>poetry install\n</code></pre></p> </li> <li> <p>Activate the Environment:    To work within the UNSAT environment, activate the virtual environment created by Poetry:    <pre><code>poetry shell\n</code></pre>    Alternatively, you can run commands within this environment by prefixing them with <code>poetry run</code>.</p> </li> </ol> <p>For more details on Poetry, visit the Poetry Documentation.</p>"},{"location":"#snellius-installation","title":"Snellius Installation","text":"<p>If you're working on the Snellius supercomputer, you'll need to load specific modules before installation. Follow these steps:</p> <ol> <li> <p>Load Required Modules:    <pre><code>module load 2023\nmodule load Python/3.11.3-GCCcore-12.3.0\n</code></pre></p> </li> <li> <p>Install UNSAT:    After loading the modules, follow the general installation steps as described in the Poetry Installation Guide.</p> </li> </ol> <p>For detailed instructions on submitting jobs on Snellius, refer to the Snellius Usage Section.</p>"},{"location":"#usage-instructions","title":"Usage Instructions","text":"<p>Once you've installed UNSAT, you're ready to start running experiments. This section will guide you through the process.</p>"},{"location":"#running-experiments","title":"Running Experiments","text":"<p>To run a basic experiment with UNSAT, navigate to the project directory and execute the following command:</p> <pre><code>poetry run python unsat/main.py fit -c configs/test_config.yaml --data.hdf5_path &lt;path to data&gt;\n</code></pre> <p>This command will start a short training session using the specified configuration file and data path. The results will be automatically uploaded to Weights and Biases. To understand and tailor your model configuration refer to this page of the manual of unsat.</p>"},{"location":"#weights-and-biases-setup","title":"Weights and Biases Setup","text":"<p>Weights and Biases (wandb) is a powerful tool for tracking machine learning experiments. To set up wandb with UNSAT:</p> <ol> <li> <p>Login to wandb:    <pre><code>poetry run wandb login\n</code></pre></p> </li> <li> <p>Enter Your API Key:    You can find your API key here. Paste it when prompted.</p> </li> </ol> <p>For more detailed guidance, visit the Weights and Biases Quickstart Guide.</p>"},{"location":"#configuration-management","title":"Configuration Management","text":"<p>UNSAT is highly configurable, allowing you to tailor the system's behavior to your specific needs. All configurations are managed via YAML files, which can be easily edited or overridden. To understand and tailor your model configuration refer to this page of the manual of unsat.</p>"},{"location":"#overriding-configurations","title":"Overriding Configurations","text":"<p>You can override default configurations by passing additional config files or command-line arguments. For example, to specify a different profiler, you can run:</p> <pre><code>poetry run python unsat/main.py fit -c configs/test_config.yaml --trainer.profiler pytorch\n</code></pre>"},{"location":"#profiling-options","title":"Profiling Options","text":"<p>Profiling your runs can help you optimize performance. UNSAT supports multiple profiling tools and configurations. To enable a predefined profiler, use the following command:</p> <pre><code>poetry run python unsat/main.py fit -c configs/profiler.yaml\n</code></pre> <p>You can mix and match configurations as needed to achieve the desired results.</p>"},{"location":"#snellius-usage","title":"Snellius Usage","text":"<p>To run experiments on Snellius, use the provided SLURM script. Here's how:</p> <ol> <li> <p>Submit a Job:    From the top-level project directory, execute:    <pre><code>sbatch scripts/run.slurm configs/test_config.yaml\n</code></pre></p> </li> <li> <p>Check Outputs:    After the job completes, various outputs will be generated:</p> </li> <li>logs_slurm/: Contains terminal outputs.</li> <li>wandb/: Metadata synchronized with Weights and Biases.</li> <li>project-unsat/: Model checkpoints and other locally stored data.</li> </ol> <p>For more advanced usage and troubleshooting on Snellius, consult the Snellius Documentation.</p>"},{"location":"#contributing-to-unsat","title":"Contributing to UNSAT","text":"<p>We welcome contributions from the community! To maintain code quality and consistency, please adhere to the following guidelines.</p>"},{"location":"#using-the-linter","title":"Using the Linter","text":"<p>Our project uses a linter to enforce code quality. The linter runs automatically on each commit to GitHub. If you'd like to run the linter locally:</p> <ol> <li> <p>Activate Your Environment:    <pre><code>poetry shell\n</code></pre></p> </li> <li> <p>Install Pre-commit:    <pre><code>pre-commit install\n</code></pre></p> </li> </ol> <p>The linter will automatically run after each commit, and it will suggest or apply fixes where necessary. Note that you may need to stage and commit the changes again after the linter has made adjustments.</p>"},{"location":"#contributing-guidelines","title":"Contributing Guidelines","text":"<p>Please follow our Contribution Guidelines when submitting pull requests. Ensure your code is well-documented, tested, and adheres to the project's coding standards.</p>"},{"location":"2dvs3d/","title":"U-net 2d vs 3d","text":""},{"location":"2dvs3d/#using-u-net-in-2d-and-3d","title":"Using U-Net in 2D and 3D","text":"<p>From the configuration file, the U-Net model can be configured to operate in either 2D or 3D by simply adjusting the <code>dimension</code> parameter. This flexibility allows you to choose the appropriate model architecture based on the nature of your data.</p>"},{"location":"2dvs3d/#configuration-overview","title":"Configuration Overview","text":"<p>The <code>dimension</code> parameter is located under the <code>data</code> section of your configuration file. By default, this is set to <code>2</code>, which configures the U-Net model to work with 2D data. To switch to a 3D U-Net model, you only need to change this value to <code>3</code>.</p>"},{"location":"2dvs3d/#example-configuration-for-2d-u-net","title":"Example Configuration for 2D U-Net","text":"<pre><code>data:\n  dimension: 2\n  # other parameters\n  patch_size: 512\n  # additional settings\n</code></pre>"},{"location":"2dvs3d/#example-configuration-for-3d-u-net","title":"Example Configuration for 3D U-Net","text":"<pre><code>data:\n  dimension: 3\n  # other parameters\n  patch_size: 64  # Typical size for 3D patches\n  # additional settings\n</code></pre>"},{"location":"2dvs3d/#how-it-works","title":"How It Works","text":"<ul> <li>2D U-Net: When <code>dimension: 2</code>, the model operates on 2D slices of your data, making it ideal for tasks like image segmentation where each input is a 2D image.</li> <li>3D U-Net: When <code>dimension: 3</code>, the model processes 3D volumes, which is useful for 3D medical imaging or volumetric data where spatial context across multiple planes is important.</li> </ul>"},{"location":"2dvs3d/#patch-size-considerations","title":"Patch Size Considerations","text":"<p>When switching to 3D, it\u2019s often necessary to adjust the <code>patch_size</code> parameter due to the increased computational complexity. For 3D data, a smaller patch size is typically used to keep memory usage manageable.</p>"},{"location":"2dvs3d/#summary","title":"Summary","text":"<p>By changing the <code>dimension</code> parameter in your configuration, you can easily switch between 2D and 3D U-Net models. This simple adjustment allows the same pipeline to handle both 2D and 3D data with minimal changes, making your setup versatile and adaptable to various types of data.</p>"},{"location":"CODE_OF_CONDUCT/","title":"Contributor Covenant Code of Conduct","text":""},{"location":"CODE_OF_CONDUCT/#our-pledge","title":"Our Pledge","text":"<p>We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation.</p> <p>We pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community.</p>"},{"location":"CODE_OF_CONDUCT/#our-standards","title":"Our Standards","text":"<p>Examples of behavior that contributes to a positive environment for our community include:</p> <ul> <li>Demonstrating empathy and kindness toward other people</li> <li>Being respectful of differing opinions, viewpoints, and experiences</li> <li>Giving and gracefully accepting constructive feedback</li> <li>Accepting responsibility and apologizing to those affected by our mistakes,   and learning from the experience</li> <li>Focusing on what is best not just for us as individuals, but for the   overall community</li> </ul> <p>Examples of unacceptable behavior include:</p> <ul> <li>The use of sexualized language or imagery, and sexual attention or   advances of any kind</li> <li>Trolling, insulting or derogatory comments, and personal or political attacks</li> <li>Public or private harassment</li> <li>Publishing others' private information, such as a physical or email   address, without their explicit permission</li> <li>Other conduct which could reasonably be considered inappropriate in a   professional setting</li> </ul>"},{"location":"CODE_OF_CONDUCT/#enforcement-responsibilities","title":"Enforcement Responsibilities","text":"<p>Community leaders are responsible for clarifying and enforcing our standards of acceptable behavior and will take appropriate and fair corrective action in response to any behavior that they deem inappropriate, threatening, offensive, or harmful.</p> <p>Community leaders have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, and will communicate reasons for moderation decisions when appropriate.</p>"},{"location":"CODE_OF_CONDUCT/#scope","title":"Scope","text":"<p>This Code of Conduct applies within all community spaces, and also applies when an individual is officially representing the community in public spaces. Examples of representing our community include using an official e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event.</p>"},{"location":"CODE_OF_CONDUCT/#enforcement","title":"Enforcement","text":"<p>Instances of abusive, harassing, or otherwise unacceptable behavior may be reported to the community leaders responsible for enforcement at s.ciarella@esciencecenter.nl. All complaints will be reviewed and investigated promptly and fairly.</p> <p>All community leaders are obligated to respect the privacy and security of the reporter of any incident.</p>"},{"location":"CODE_OF_CONDUCT/#enforcement-guidelines","title":"Enforcement Guidelines","text":"<p>Community leaders will follow these Community Impact Guidelines in determining the consequences for any action they deem in violation of this Code of Conduct:</p>"},{"location":"CODE_OF_CONDUCT/#1-correction","title":"1. Correction","text":"<p>Community Impact: Use of inappropriate language or other behavior deemed unprofessional or unwelcome in the community.</p> <p>Consequence: A private, written warning from community leaders, providing clarity around the nature of the violation and an explanation of why the behavior was inappropriate. A public apology may be requested.</p>"},{"location":"CODE_OF_CONDUCT/#2-warning","title":"2. Warning","text":"<p>Community Impact: A violation through a single incident or series of actions.</p> <p>Consequence: A warning with consequences for continued behavior. No interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, for a specified period of time. This includes avoiding interactions in community spaces as well as external channels like social media. Violating these terms may lead to a temporary or permanent ban.</p>"},{"location":"CODE_OF_CONDUCT/#3-temporary-ban","title":"3. Temporary Ban","text":"<p>Community Impact: A serious violation of community standards, including sustained inappropriate behavior.</p> <p>Consequence: A temporary ban from any sort of interaction or public communication with the community for a specified period of time. No public or private interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, is allowed during this period. Violating these terms may lead to a permanent ban.</p>"},{"location":"CODE_OF_CONDUCT/#4-permanent-ban","title":"4. Permanent Ban","text":"<p>Community Impact: Demonstrating a pattern of violation of community standards, including sustained inappropriate behavior,  harassment of an individual, or aggression toward or disparagement of classes of individuals.</p> <p>Consequence: A permanent ban from any sort of public interaction within the community.</p>"},{"location":"CODE_OF_CONDUCT/#attribution","title":"Attribution","text":"<p>This Code of Conduct is adapted from the Contributor Covenant, version 2.0, available at https://www.contributor-covenant.org/version/2/0/code_of_conduct.html.</p> <p>Community Impact Guidelines were inspired by Mozilla's code of conduct enforcement ladder.</p> <p>For answers to common questions about this code of conduct, see the FAQ at https://www.contributor-covenant.org/faq. Translations are available at https://www.contributor-covenant.org/translations.</p>"},{"location":"CONTRIBUTING/","title":"Contributing guidelines","text":"<p>Welcome! unsat is an open-source project for analysis of rooted soil. If you're trying unsat with your data, your experience, questions, bugs you encountered, and suggestions for improvement are important to the success of the project.</p> <p>We have a Code of Conduct, please follow it in all your interactions with the project.</p>"},{"location":"CONTRIBUTING/#questions-feedback-bugs","title":"Questions, feedback, bugs","text":"<p>Use the search function to see if someone else already ran across the same issue. Feel free to open a new issue here to ask a question, suggest improvements/new features, or report any bugs that you ran into.</p>"},{"location":"CONTRIBUTING/#submitting-changes","title":"Submitting changes","text":"<p>Even better than a good bug report is a fix for the bug or the implementation of a new feature. We welcome any contributions that help improve the code.</p> <p>When contributing to this repository, please first discuss the change you wish to make via an issue with the owners of this repository before making a change.</p> <p>Contributions can come in the form of:</p> <ul> <li>Bug fixes</li> <li>New features</li> <li>Improvement of existing code</li> <li>Updates to the documentation</li> <li>... ?</li> </ul> <p>We use the usual GitHub pull-request flow. For more info see GitHub's own documentation.</p> <p>Typically this means:</p> <ol> <li>Forking the repository and/or make a new branch</li> <li>Making your changes</li> <li>Make sure that the tests pass and add your own</li> <li>Update the documentation is updated for new features</li> <li>Pushing the code back to Github</li> <li>Create a new Pull Request</li> </ol> <p>One of the code owners will review your code and request changes if needed. Once your changes have been approved, your contributions will become part of unsat. \ud83c\udf89</p>"},{"location":"config/","title":"Configuration Parameters","text":"<p>This page describes the configuration parameters used in the YAML file for controlling the training and evaluation of the model.</p> <p>This is what a standard configuration looks like: <pre><code># lightning.pytorch==2.1.2\nseed_everything: true\ntrainer:\n  accelerator: gpu\n  strategy: auto\n  devices: auto\n  num_nodes: 1\n  precision: null\n  logger:\n    class_path: lightning.pytorch.loggers.WandbLogger\n    init_args:\n      name: null\n      save_dir: null\n      version: null\n      offline: false\n      dir: null\n      id: null\n      anonymous: null\n      project: project-unsat\n      log_model: false\n      experiment: null\n      prefix: ''\n      checkpoint_name: null\n      job_type: null\n      config: null\n      entity: null\n      reinit: null\n      tags: null\n      group: null\n      notes: null\n      magic: null\n      config_exclude_keys: null\n      config_include_keys: null\n      mode: null\n      allow_val_change: null\n      resume: null\n      force: null\n      tensorboard: null\n      sync_tensorboard: null\n      monitor_gym: null\n      save_code: null\n      settings: null\n  callbacks:\n  - unsat.callbacks.ClassWeightsCallback\n  - class_path: unsat.callbacks.CheckFaultsCallback\n    init_args:\n      patch_size: 64\n  fast_dev_run: false\n  max_epochs: 1000\n  min_epochs: null\n  max_steps: -1\n  min_steps: null\n  max_time: null\n  limit_train_batches: null\n  limit_val_batches: null\n  limit_test_batches: null\n  limit_predict_batches: null\n  overfit_batches: 0.0\n  val_check_interval: null\n  check_val_every_n_epoch: 1\n  num_sanity_val_steps: null\n  log_every_n_steps: 1\n  enable_checkpointing: null\n  enable_progress_bar: null\n  enable_model_summary: null\n  accumulate_grad_batches: 1\n  gradient_clip_val: null\n  gradient_clip_algorithm: null\n  deterministic: null\n  benchmark: null\n  inference_mode: true\n  use_distributed_sampler: true\n  profiler: null\n  detect_anomaly: false\n  barebones: false\n  plugins: null\n  sync_batchnorm: false\n  reload_dataloaders_every_n_epochs: 0\n  default_root_dir: null\nmodel:\n  network:\n    class_path: unsat.models.UNet\n    init_args:\n      start_channels: 2\n      num_blocks: 3\n      kernel_size: 3\n      block_depth: 2\n      batch_norm: true\n  optimizer:\n    class_path: torch.optim.Adam\n    init_args:\n      lr: 3e-3\ndata:\n  hdf5_path: /projects/0/einf3381/UNSAT/data/experimental.h5\n  faults_path: faults/faults.yaml\n  class_names:\n  - \"water\"\n  - \"background\"\n  - \"air\"\n  - \"root\"\n  - \"soil\"\n  input_channels: 1\n  train_samples:\n  - maize/coarse/loose\n  - maize/fine/dense\n  height_range:\n  - 1000\n  - 1100\n  train_day_range:\n  - 2\n  - 3\n  validation_split: 0.1\n  seed: 42\n  batch_size: 4\n  num_workers: 2\n  dimension: 2\n  patch_size: 512\n  patch_border: 16\nckpt_path: null\n</code></pre></p>"},{"location":"config/#configuration-parameters_1","title":"Configuration Parameters","text":""},{"location":"config/#explanation-of-configuration-parameters","title":"Explanation of Configuration Parameters","text":"<ul> <li>seed_everything: Ensures all random number generators are seeded to enable reproducibility. (true or false)</li> </ul>"},{"location":"config/#trainer-configuration","title":"Trainer Configuration","text":"<ul> <li>trainer.accelerator: Specifies the hardware to use for training (gpu, cpu, etc.).</li> <li>trainer.strategy: Automatically determines the best distributed training strategy.</li> <li>trainer.devices: Sets the number of devices to use. <code>auto</code> uses all available devices.</li> <li>trainer.num_nodes: Specifies the number of nodes for distributed training.</li> <li>trainer.precision: Defines the floating-point precision. <code>null</code> uses the default (32-bit).</li> </ul>"},{"location":"config/#logger-settings","title":"Logger Settings","text":"<ul> <li>trainer.logger.class_path: Specifies the logger to use. This setup uses the <code>WandbLogger</code>.</li> <li>trainer.logger.init_args: Arguments for initializing the logger.</li> <li>name: Name for the run. <code>null</code> auto-generates a name.</li> <li>save_dir: Directory to save logs.</li> <li>version: Version number for the logger.</li> <li>offline: Enables offline mode for logging.</li> <li>dir: Directory for logs.</li> <li>id: ID for resuming a run.</li> <li>anonymous: Logs anonymously if set to true.</li> <li>project: Project name. Defaults to <code>project-unsat</code>.</li> <li>log_model: Indicates whether to log model checkpoints.</li> <li>experiment: Name or identifier for the experiment.</li> <li>prefix: Prefix for run names.</li> <li>checkpoint_name: Name of the checkpoint.</li> <li>job_type: Specifies the job type (e.g., training, validation).</li> <li>config: Logs a configuration dictionary.</li> <li>entity: W&amp;B entity or team name.</li> <li>reinit: Allows re-initialization if set to true.</li> <li>tags: Tags for the run.</li> <li>group: Group name for organizing runs.</li> <li>notes: Additional notes about the run.</li> <li>magic: Magic commands.</li> <li>config_exclude_keys: Excludes specific keys from the config logging.</li> <li>config_include_keys: Includes specific keys in the config logging.</li> <li>mode: Sets the mode for the logger.</li> <li>allow_val_change: Allows changing validation configuration if true.</li> <li>resume: Resumes a previous run if true.</li> <li>force: Forces overwriting an existing run.</li> <li>tensorboard: Configures TensorBoard integration.</li> <li>sync_tensorboard: Synchronizes TensorBoard with the logger.</li> <li>monitor_gym: Monitors the gym environment if true.</li> <li>save_code: Saves the code related to the run if true.</li> <li>settings: Additional logger settings.</li> </ul>"},{"location":"config/#callbacks","title":"Callbacks","text":"<ul> <li>trainer.callbacks: A list of callbacks used during training.</li> <li>unsat.callbacks.ClassWeightsCallback: Adjusts class weights dynamically.</li> <li>unsat.callbacks.CheckFaultsCallback: Monitors for faults during training.<ul> <li>init_args.patch_size: Patch size for fault checking, set to 64.</li> </ul> </li> </ul>"},{"location":"config/#additional-trainer-settings","title":"Additional Trainer Settings","text":"<ul> <li>trainer.fast_dev_run: Runs a single batch for debugging if true.</li> <li>trainer.max_epochs: Maximum number of epochs, set to 1000.</li> <li>trainer.min_epochs: Minimum number of epochs. <code>null</code> means no minimum.</li> <li>trainer.max_steps: Maximum training steps, set to -1 to disable.</li> <li>trainer.min_steps: Minimum number of steps. <code>null</code> means no minimum.</li> <li>trainer.max_time: Limits the maximum training time.</li> <li>trainer.limit_train_batches: Limits the number of training batches per epoch.</li> <li>trainer.limit_val_batches: Limits the number of validation batches per epoch.</li> <li>trainer.limit_test_batches: Limits the number of test batches.</li> <li>trainer.limit_predict_batches: Limits the number of prediction batches.</li> <li>trainer.overfit_batches: Fraction of data to overfit for debugging, set to 0.0.</li> <li>trainer.val_check_interval: How often to validate, in terms of training epochs.</li> <li>trainer.check_val_every_n_epoch: How often to perform validation checks, in epochs.</li> <li>trainer.num_sanity_val_steps: Number of steps for sanity check validation.</li> <li>trainer.log_every_n_steps: Frequency of logging, set to 1 for every step.</li> <li>trainer.enable_checkpointing: Enables checkpointing.</li> <li>trainer.enable_progress_bar: Shows a progress bar if true.</li> <li>trainer.enable_model_summary: Displays a summary of the model if true.</li> <li>trainer.accumulate_grad_batches: Number of batches over which gradients are accumulated, set to 1.</li> <li>trainer.gradient_clip_val: Clipping value for gradients.</li> <li>trainer.gradient_clip_algorithm: Algorithm used for gradient clipping.</li> <li>trainer.deterministic: Ensures deterministic training if true.</li> <li>trainer.benchmark: Enables benchmarking for better performance.</li> <li>trainer.inference_mode: Enables inference mode, optimizing evaluation.</li> <li>trainer.use_distributed_sampler: Uses a distributed sampler for data loading.</li> <li>trainer.profiler: Profiler for performance analysis.</li> <li>trainer.detect_anomaly: Enables anomaly detection if true.</li> <li>trainer.barebones: If true, runs with minimal features.</li> <li>trainer.plugins: Specifies additional plugins to use.</li> <li>trainer.sync_batchnorm: Synchronizes batch normalization across devices if true.</li> <li>trainer.reload_dataloaders_every_n_epochs: Reloads data loaders after a specified number of epochs.</li> <li>trainer.default_root_dir: Root directory for saving logs and checkpoints.</li> </ul>"},{"location":"config/#model-configuration","title":"Model Configuration","text":"<ul> <li>model.network.class_path: Path to the model class, set to <code>unsat.models.UNet</code>.</li> <li>model.network.init_args: Initialization arguments for the model.</li> <li>start_channels: Number of starting channels, set to 2.</li> <li>num_blocks: Number of blocks in the model, set to 3.</li> <li>kernel_size: Size of the convolution kernels, set to 3.</li> <li>block_depth: Depth of each block, set to 2.</li> <li>batch_norm: Enables batch normalization if true.</li> </ul>"},{"location":"config/#optimizer-configuration","title":"Optimizer Configuration","text":"<ul> <li>model.optimizer.class_path: Path to the optimizer class, set to <code>torch.optim.Adam</code>.</li> <li>model.optimizer.init_args: Initialization arguments for the optimizer.</li> <li>lr: Learning rate, set to 3e-3.</li> </ul>"},{"location":"config/#data-configuration","title":"Data Configuration","text":"<ul> <li>data.hdf5_path: Path to the HDF5 file containing the dataset.</li> <li>data.faults_path: Path to the YAML file specifying faults.</li> <li>data.class_names: List of class names for classification:</li> <li>water, background, air, root, soil</li> <li>data.input_channels: Number of input channels, set to 1.</li> <li>data.train_samples: List of paths to training samples:</li> <li>maize/coarse/loose, maize/fine/dense</li> <li>data.height_range: Range of heights to consider, from 1000 to 1100.</li> <li>data.train_day_range: Days to include in the training set, from 2 to 3.</li> <li>data.validation_split: Fraction of the data to use for validation, set to 0.1.</li> <li>data.seed: Random seed for data shuffling, set to 42.</li> <li>data.batch_size: Batch size, set to 4.</li> <li>data.num_workers: Number of workers for data loading, set to 2.</li> <li>data.dimension: Dimensionality of the data, set to 2.</li> <li>data.patch_size: Patch size for data extraction, set to 512.</li> <li>data.patch_border: Border size around each patch, set to 16.</li> </ul>"},{"location":"config/#checkpoint-path","title":"Checkpoint Path","text":"<ul> <li>ckpt_path: Path to a checkpoint for resuming training, set to <code>null</code> to start fresh.</li> </ul>"},{"location":"data/","title":"Converting TIFF to HDF5 Using XrayTIFF2h5","text":"<p>To convert your input TIFF files into HDF5 format, we recommend using the XrayTIFF2h5 library. This tool is specifically designed to handle the conversion process efficiently and is easy to integrate into <code>unsat</code> workflow.</p>"},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#installation-guide","title":"Installation Guide","text":""},{"location":"installation/#using-poetry-recommended","title":"Using Poetry (Recommended)","text":"<p>Poetry is a dependency management tool that helps you manage your Python environments and dependencies efficiently. We highly recommend using Poetry to set up UNSAT. Follow these steps to get started:</p> <ol> <li> <p>Running on Snellius? Read first the subsection below</p> </li> <li> <p>Clone the Repository:    First, clone the UNSAT repository to your local machine:    <pre><code>git clone https://github.com/UNSAT3D/unsat.git\n</code></pre></p> </li> <li> <p>Navigate to the Project Folder:    Move into the cloned repository directory:    <pre><code>cd unsat\n</code></pre></p> </li> <li> <p>Install Poetry:    If Poetry is not already installed on your system, you can install it using pip:    <pre><code>pip install poetry\n</code></pre></p> </li> <li> <p>Install Dependencies:    Run the following command to install all required dependencies:    <pre><code>poetry install\n</code></pre></p> </li> <li> <p>Activate the Environment:    To work within the UNSAT environment, activate the virtual environment created by Poetry:    <pre><code>poetry shell\n</code></pre>    Alternatively, you can run commands within this environment by prefixing them with <code>poetry run</code>.</p> </li> </ol> <p>For more details on Poetry, visit the Poetry Documentation.</p>"},{"location":"installation/#snellius-installation","title":"Snellius Installation","text":"<p>If you're working on the Snellius supercomputer, you'll need to load specific modules before installation. Follow these steps:</p> <ol> <li> <p>Load Required Modules:    <pre><code>module load 2023\nmodule load Python/3.11.3-GCCcore-12.3.0\n</code></pre></p> </li> <li> <p>Install UNSAT:    After loading the modules, follow the general installation steps as described in the Poetry Installation Guide.</p> </li> </ol> <p>For detailed instructions on submitting jobs on Snellius, refer to the Snellius Usage Section.</p>"},{"location":"usage/","title":"Usage","text":""},{"location":"usage/#usage-instructions","title":"Usage Instructions","text":"<p>Once you've installed UNSAT, you're ready to start running experiments. This section will guide you through the process.</p>"},{"location":"usage/#running-experiments","title":"Running Experiments","text":"<p>To run a basic experiment with UNSAT, navigate to the project directory and execute the following command:</p> <pre><code>poetry run python unsat/main.py fit -c configs/test_config.yaml --data.hdf5_path &lt;path to data&gt;\n</code></pre> <p>This command will start a short training session using the specified configuration file and data path. The results will be automatically uploaded to Weights and Biases. To understand and tailor your model configuration refer to this page of the manual of unsat.</p>"},{"location":"usage/#weights-and-biases-setup","title":"Weights and Biases Setup","text":"<p>Weights and Biases (wandb) is a powerful tool for tracking machine learning experiments. To set up wandb with UNSAT:</p> <ol> <li> <p>Login to wandb:    <pre><code>poetry run wandb login\n</code></pre></p> </li> <li> <p>Enter Your API Key:    You can find your API key here. Paste it when prompted.</p> </li> </ol> <p>For more detailed guidance, visit the Weights and Biases Quickstart Guide.</p>"},{"location":"api/api/","title":"unsat","text":"<ul> <li>unsat.train</li> </ul>"},{"location":"api/train/","title":"train","text":""},{"location":"api/train/#unsat.train.Autoencoder","title":"<code>Autoencoder(base_channel_size, latent_dim, encoder_class=Encoder, decoder_class=Decoder, num_input_channels=3, width=32, height=32)</code>","text":"<p>               Bases: <code>LightningModule</code></p> Source code in <code>unsat/train.py</code> <pre><code>def __init__(\n    self,\n    base_channel_size: int,\n    latent_dim: int,\n    encoder_class: object = Encoder,\n    decoder_class: object = Decoder,\n    num_input_channels: int = 3,\n    width: int = 32,\n    height: int = 32,\n):\n    super().__init__()\n    # Saving hyperparameters of autoencoder\n    self.save_hyperparameters()\n    # Creating encoder and decoder\n    self.encoder = encoder_class(num_input_channels, base_channel_size, latent_dim)\n    self.decoder = decoder_class(num_input_channels, base_channel_size, latent_dim)\n    # Example input array needed for visualizing the graph of the network\n    self.example_input_array = torch.zeros(2, num_input_channels, width, height)\n</code></pre>"},{"location":"api/train/#unsat.train.Autoencoder.forward","title":"<code>forward(x)</code>","text":"<p>The forward function takes in an image and returns the reconstructed image.</p> Source code in <code>unsat/train.py</code> <pre><code>def forward(self, x):\n    \"\"\"The forward function takes in an image and returns the reconstructed image.\"\"\"\n    print(x.shape, flush=True)\n    breakpoint()\n    z = self.encoder(x)\n    x_hat = self.decoder(z)\n    return x_hat\n</code></pre>"},{"location":"api/train/#unsat.train.LightningTrainer","title":"<code>LightningTrainer(network, class_names, dimension, input_channels, optimizer, **kwargs)</code>","text":"<p>               Bases: <code>LightningModule</code></p> <p>Args:     network (nn.Module):         The network to train.     class_names (List[str]):         The names of the classes.     dimension (int):         The number of spatial dimensions.     input_channels (int):         The number of input channels.</p> Source code in <code>unsat/train.py</code> <pre><code>def __init__(\n    self,\n    network,\n    class_names,\n    dimension,\n    input_channels,\n    optimizer: OptimizerCallable,\n    **kwargs,\n):\n    \"\"\"\n    Lightning module defining the network and the training loop.\n\n    Args:\n        network (nn.Module):\n            The network to train.\n        class_names (List[str]):\n            The names of the classes.\n        dimension (int):\n            The number of spatial dimensions.\n        input_channels (int):\n            The number of input channels.\n    \"\"\"\n    torch.autograd.set_detect_anomaly(True)\n    super().__init__()\n    self.optimizer = optimizer\n\n    self.class_names = class_names\n    self.num_classes = len(class_names)\n\n    self.network = network\n    self.network.dimension = dimension\n    self.network.num_classes = self.num_classes\n    self.network.input_channels = input_channels\n    self.network.build()\n\n    metrics_args = dict(task=\"multiclass\", num_classes=self.num_classes, ignore_index=-1)\n    self.metrics = torch.nn.ModuleDict()\n    self.metrics[\"acc\"] = torch.nn.ModuleDict(\n        {\n            \"train_\": Accuracy(**metrics_args, average=\"macro\"),\n            \"val_\": Accuracy(**metrics_args, average=\"macro\"),\n        }\n    )\n    self.metrics[\"f1\"] = torch.nn.ModuleDict(\n        {\n            \"train_\": F1Score(**metrics_args, average=\"macro\"),\n            \"val_\": F1Score(**metrics_args, average=\"macro\"),\n        }\n    )\n    self.metrics[\"acc_per_class\"] = torch.nn.ModuleDict(\n        {\n            \"train_\": ClasswiseWrapper(\n                Accuracy(**metrics_args, average=None), labels=self.class_names\n            ),\n            \"val_\": ClasswiseWrapper(\n                Accuracy(**metrics_args, average=None), labels=self.class_names\n            ),\n        }\n    )\n    self.metrics[\"f1_per_class\"] = torch.nn.ModuleDict(\n        {\n            \"train_\": ClasswiseWrapper(\n                F1Score(**metrics_args, average=None), labels=self.class_names\n            ),\n            \"val_\": ClasswiseWrapper(\n                F1Score(**metrics_args, average=None), labels=self.class_names\n            ),\n        }\n    )\n\n    metrics_args[\"normalize\"] = \"true\"\n    self.metrics[\"confusion\"] = torch.nn.ModuleDict(\n        {\"train_\": ConfusionMatrix(**metrics_args), \"val_\": ConfusionMatrix(**metrics_args)}\n    )\n\n    # These can be overriden to represent class frequencies by using the ClassWeightsCallback\n    self.class_weights = torch.ones(self.num_classes)\n</code></pre>"},{"location":"api/train/#unsat.train.WandbSaveConfigCallback","title":"<code>WandbSaveConfigCallback</code>","text":"<p>               Bases: <code>SaveConfigCallback</code></p> <p>Custom callback to save the lightning config to wandb.</p>"},{"location":"notebooks/visualization/","title":"Small visualization example","text":"In\u00a0[3]: Copied! <pre>from unsat.io import tif_to_numpy\nfrom unsat.plot import plot_slice, slicer\nfrom unsat.Sampler import RectangularSampler\nimport matplotlib.pyplot as plt\nimport os\n</pre> from unsat.io import tif_to_numpy from unsat.plot import plot_slice, slicer from unsat.Sampler import RectangularSampler import matplotlib.pyplot as plt import os In\u00a0[4]: Copied! <pre>PATH = \"../data/\"\nEXAMPLE = os.path.join(PATH, \"exp\", \"CoarseSand_Day2Growth.tif\")\n</pre> PATH = \"../data/\" EXAMPLE = os.path.join(PATH, \"exp\", \"CoarseSand_Day2Growth.tif\") In\u00a0[5]: Copied! <pre>example_np = tif_to_numpy(EXAMPLE)\n</pre> example_np = tif_to_numpy(EXAMPLE) In\u00a0[6]: Copied! <pre>plot_slice(example_np, 300, 0)\n</pre> plot_slice(example_np, 300, 0) Out[6]: <pre>&lt;matplotlib.image.AxesImage at 0x7f7df86d09a0&gt;</pre> In\u00a0[7]: Copied! <pre>slice2d = slicer(example_np, 300, 1)  # Create a 2D array by sampling the 3D one\nsam = RectangularSampler(slice2d, loc=[100, 200], size=[300, 400])\nsam.plot()\n</pre> slice2d = slicer(example_np, 300, 1)  # Create a 2D array by sampling the 3D one sam = RectangularSampler(slice2d, loc=[100, 200], size=[300, 400]) sam.plot() <p>Extract the sampling area:</p> In\u00a0[8]: Copied! <pre>snap = sam.sample()\nplt.imshow(snap)\n</pre> snap = sam.sample() plt.imshow(snap) Out[8]: <pre>&lt;matplotlib.image.AxesImage at 0x7f7df4a311b0&gt;</pre> <p>Check if the sampling area is out of bounds:</p> In\u00a0[9]: Copied! <pre>sam.is_out()\n</pre> sam.is_out() Out[9]: <pre>False</pre>"},{"location":"notebooks/visualization/#small-visualization-example","title":"Small visualization example\u00b6","text":""},{"location":"notebooks/visualization/#import-required-packages","title":"Import required packages\u00b6","text":""},{"location":"notebooks/visualization/#set-up-variables","title":"Set-up variables\u00b6","text":""},{"location":"notebooks/visualization/#store-as-numpy-array","title":"Store as <code>numpy</code> array\u00b6","text":"<p>And explore some slices.</p>"},{"location":"notebooks/visualization/#use-slicer-and-samplers","title":"Use slicer and samplers\u00b6","text":"<ul> <li><code>slicer</code> is just a wrapper for easy slicing</li> <li><code>Sampler</code> class and subclasses contain functions for easy sampling</li> </ul>"}]}